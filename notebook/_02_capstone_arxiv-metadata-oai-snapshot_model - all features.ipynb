{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1728d35e",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1742256520839,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "1728d35e"
   },
   "outputs": [],
   "source": [
    "### CAPSTONE PROJECT - 2025 - ARXIV.ORG METADATA - PREDICT PUBLICATION AND SELECT HIGHER QUALITY PAPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33c45a5-bb6e-4b6e-b7d4-020801a34797",
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1742256520891,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "c33c45a5-bb6e-4b6e-b7d4-020801a34797"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "import re\n",
    "import ast\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "### Word Cloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "### Modelling Libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "\n",
    "#SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2267e999-9870-4a88-b678-b47ab2e7e8fa",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1742256520935,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "2267e999-9870-4a88-b678-b47ab2e7e8fa"
   },
   "outputs": [],
   "source": [
    "#### 1. Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9087d6-fbb1-4a60-92a0-f9ec15af17b4",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1742256520937,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "4a9087d6-fbb1-4a60-92a0-f9ec15af17b4"
   },
   "outputs": [],
   "source": [
    "###Overview of the Question to Be Solved:\n",
    "#This project aims to predict if a paper on arxiv.org is going to be published or not in a research magazine.\n",
    "#Primary question: “How can we effectively classify the Arxiv papers and predict if the paper is going to be published or not?\"\n",
    "# Target variable: a binary response (y) for the paper being published or not.\n",
    "# Data sources: arxiv.org dataset for the subset catgeory \"cs.AI\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3197eb-83c4-47b2-bf99-06d66ff7b33e",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742256520939,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "0f3197eb-83c4-47b2-bf99-06d66ff7b33e"
   },
   "outputs": [],
   "source": [
    "###Capstone Project Overview - Predicting if a research paper on arxiv.org will be published or not to select the high quality papers.\n",
    "\n",
    "#The research question you intend to answer:\n",
    "# - \"To predict if a paper on arxiv.org is going to be published or not in a research magazine to help select the higher quality papers\".\n",
    "\n",
    "#Expected data source(s):\n",
    "# - Two arxiv.org metadata files from the following sources:\n",
    "#   - https://www.kaggle.com/datasets/Cornell-University/arxiv (filename = arxiv-metadata-oai-snapshot.json);\n",
    "#   - https://www.kaggle.com/datasets/spsayakpaul/arxiv-paper-abstracts (filename = arxi_data.csv)\n",
    "\n",
    "#The techniques expected to be used in my analysis:\n",
    "# - TF-IDF (Term Frequency-Inverse Document Frequency) for embeedings on title and abstract data\n",
    "# - BERT for embeedings on title and abstract data\n",
    "# - Word Cloud and Word Count to understand the title and abstract\n",
    "# - PCA, K-means clustering, feature selection and hyperparameter tunning\n",
    "# - Predictive modeling\n",
    "#   - Techquines to be used for predictive modeling:\n",
    "#     - Logistic Regression\n",
    "#     - Decision Tree\n",
    "#     - Random Forest\n",
    "#     - Support Vector Machine (SVM)\n",
    "#     - KNN: K-Nearest Neighbors\n",
    "#     - Gaussian Naive Bayes\n",
    "#     - Gradient Boosting\n",
    "#     - Neural Network\n",
    "\n",
    "#The expected results\n",
    "# - Target binary response variable (y) for an arxiv.org paper being published or not (dataset column \"journal-ref\" NaN or filled with content).\n",
    "# - The column journal-ref contains the arxiv.org \"Reference to the journal where the paper was published (if applicable)\".\n",
    "# - I assume NaN as \"not published\", and any content as \"published\".\n",
    "\n",
    "#Why this question is important\n",
    "# - As not all arxiv.org papers are actually published, this project can help researchers select the \"higher quality\" papers to read first, assuming\n",
    "#   that a \"higher quality\" paper is normally published. This will help researchers save time on searching for and reading content for their projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5101ecf-dfb7-4577-84d9-1132bbdd3f3f",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742256520941,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "f5101ecf-dfb7-4577-84d9-1132bbdd3f3f"
   },
   "outputs": [],
   "source": [
    "#### 2. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d454056-360b-469d-844c-165df158a927",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742256520943,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "3d454056-360b-469d-844c-165df158a927"
   },
   "outputs": [],
   "source": [
    "#Preprocessing ARXIV.org metadata for AI (category = 'cs.AI')\n",
    "#Source for data -- https://www.kaggle.com/datasets/Cornell-University/arxiv\n",
    "#DataSets:\n",
    "#Arxiv.org AI Research Papers Dataset: Contains metadata of 10,000 AI research papers from Arxiv.\n",
    "# - https://www.kaggle.com/datasets/spsayakpaul/arxiv-paper-abstracts\n",
    "\n",
    "#Arxiv Paper Abstracts: A dataset for building multi-label text classifiers based on Arxiv paper abstracts.\n",
    "# - https://www.kaggle.com/datasets/yasirabdaali/arxivorg-ai-research-papers-dataset\n",
    "# - https://www.kaggle.com/datasets/yasirabdaali/arxivorg-ai-research-papers-dataset?select=arxiv_ai.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb910b8a-4b69-4713-8978-90091d22230b",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742256520957,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "eb910b8a-4b69-4713-8978-90091d22230b"
   },
   "outputs": [],
   "source": [
    "#Metadata of the Arxiv.org OAI Snapshot dataset (main source)\n",
    "#id: A unique identifier for each arXiv paper.\n",
    "#submitter: The user who submitted the paper to arXiv.\n",
    "#authors: A list of authors who contributed to the paper.\n",
    "#title: The title of the paper.\n",
    "#comments: Additional comments about the paper, such as notes on revisions or submission details.\n",
    "#journal-ref: Reference to the journal where the paper was published (if applicable).\n",
    "#doi: The DOI (Digital Object Identifier) of the paper (if available).\n",
    "#report-no: Report number associated with the paper (if any).\n",
    "#categories: Categories or subjects to which the paper belongs (e.g., cs.AI, math.ST, etc.).\n",
    "#license: Licensing information for the paper.\n",
    "#abstract: A brief summary or abstract of the paper.\n",
    "#versions: Information about different versions of the paper submitted to arXiv.\n",
    "#update_date: The date when the paper was last updated on arXiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148dbd56-8bb1-4390-bdd8-1d12676338ee",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742256520962,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "148dbd56-8bb1-4390-bdd8-1d12676338ee"
   },
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "input_file = 'C:/Users/mnkub/Desktop/Capstone/data/arxiv_final.json' \n",
    "#input_file = '../data/arxiv_final.json' \n",
    "\n",
    "# Check if the input file exists\n",
    "if not os.path.exists(input_file):\n",
    "    raise FileNotFoundError(f\"File {input_file} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21730c11-f2e7-4abd-85ae-34be115ccbaa",
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1742256521394,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "21730c11-f2e7-4abd-85ae-34be115ccbaa"
   },
   "outputs": [],
   "source": [
    "#Read output file (JSON)\n",
    "arxiv = pd.read_json(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b91d613-ac5c-4b8b-8a5d-2ccdae6daea8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1742256521421,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "6b91d613-ac5c-4b8b-8a5d-2ccdae6daea8",
    "outputId": "b0108311-58f6-47ba-8e44-ec33a98670ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report_no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>...</th>\n",
       "      <th>abstract_tfidf</th>\n",
       "      <th>cluster_abstract_tfidf</th>\n",
       "      <th>title_tfidf</th>\n",
       "      <th>cluster_title_tfidf</th>\n",
       "      <th>abstract_embedding_bert</th>\n",
       "      <th>abstract_reduced_embeddings_bert</th>\n",
       "      <th>cluster_abstract_bert</th>\n",
       "      <th>title_embedding_bert</th>\n",
       "      <th>title_reduced_embeddings_bert</th>\n",
       "      <th>cluster_title_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.1394</td>\n",
       "      <td>Tarik Hadvzic</td>\n",
       "      <td>Tarik Hadzic Rune Moller Jensen Henrik Reif An...</td>\n",
       "      <td>Calculating Valid Domains for BDDBased Interac...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0707399398, 0.2497202158, 0.0697884262, -0...</td>\n",
       "      <td>[-2.0193810463, -2.4993662834, -0.3357081413, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.762732029, -0.5272296667, -0.3555475771, -...</td>\n",
       "      <td>[2.5423688889, -0.6378098726, -1.2343144417, -...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.201</td>\n",
       "      <td>Juliana Bernardes</td>\n",
       "      <td>Juliana S Bernardes Alberto Davila Vitor Santo...</td>\n",
       "      <td>A study of structural properties on profiles HMMs</td>\n",
       "      <td>6 pages, 7 figures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.3843331933, -0.2263615727, 0.2963011265, 0...</td>\n",
       "      <td>[1.3566942215, 1.1760284901, 1.6757059097, -1....</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.451326102, -0.3827941716, -0.4721180499, -...</td>\n",
       "      <td>[0.7403473854, 0.6475714445, 0.193864598900000...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.3433</td>\n",
       "      <td>Tshilidzi Marwala</td>\n",
       "      <td>Tshilidzi Marwala and Bodie Crossingham</td>\n",
       "      <td>Bayesian approach to rough set</td>\n",
       "      <td>20 pages, 3 figures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.3154313266, -0.24923917650000002, -0.32852...</td>\n",
       "      <td>[-0.27569633720000003, -2.1775341034, 2.087684...</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.48346123100000005, -0.259116143, -0.323963...</td>\n",
       "      <td>[-1.4785642624, -1.9715181589, 2.7166180611, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.3515</td>\n",
       "      <td>Jegor Uglov Mr</td>\n",
       "      <td>J Uglov V Schetinin C Maple</td>\n",
       "      <td>Comparing Robustness of Pairwise and Multiclas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.1155/2008/468693</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.040906731, 0.4251708388, -0.162817806, 0.18...</td>\n",
       "      <td>[1.2501780987, 1.6642855406, -0.07740855220000...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.5709663033, -0.6318161488, -0.868732035200...</td>\n",
       "      <td>[3.9551944733, 1.2371120453, -0.20816591380000...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.3905</td>\n",
       "      <td>Marc Schoenauer</td>\n",
       "      <td>Christian Gagne INFORMATIQUE WGZ INC Michele S...</td>\n",
       "      <td>Ensemble Learning for Free with Evolutionary A...</td>\n",
       "      <td>None</td>\n",
       "      <td>Dans GECCO (2007)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.12671619650000002, -0.0426417366, -0.20895...</td>\n",
       "      <td>[-0.2887310386, 2.3744587898000002, -0.4303132...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.4691320956, -0.2000201046, -0.2584528625, ...</td>\n",
       "      <td>[-0.4662218094, -1.8894429207, -0.305285722000...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          submitter  \\\n",
       "0  704.1394      Tarik Hadvzic   \n",
       "1   704.201  Juliana Bernardes   \n",
       "2  704.3433  Tshilidzi Marwala   \n",
       "3  704.3515     Jegor Uglov Mr   \n",
       "4  704.3905    Marc Schoenauer   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Tarik Hadzic Rune Moller Jensen Henrik Reif An...   \n",
       "1  Juliana S Bernardes Alberto Davila Vitor Santo...   \n",
       "2            Tshilidzi Marwala and Bodie Crossingham   \n",
       "3                        J Uglov V Schetinin C Maple   \n",
       "4  Christian Gagne INFORMATIQUE WGZ INC Michele S...   \n",
       "\n",
       "                                               title             comments  \\\n",
       "0  Calculating Valid Domains for BDDBased Interac...                 None   \n",
       "1  A study of structural properties on profiles HMMs   6 pages, 7 figures   \n",
       "2                     Bayesian approach to rough set  20 pages, 3 figures   \n",
       "3  Comparing Robustness of Pairwise and Multiclas...                 None   \n",
       "4  Ensemble Learning for Free with Evolutionary A...                 None   \n",
       "\n",
       "         journal_ref                  doi report_no categories  \\\n",
       "0               None                 None      None      cs.AI   \n",
       "1               None                 None      None      cs.AI   \n",
       "2               None                 None      None      cs.AI   \n",
       "3               None  10.1155/2008/468693      None      cs.AI   \n",
       "4  Dans GECCO (2007)                 None      None      cs.AI   \n",
       "\n",
       "                                             license  ...  \\\n",
       "0                                               None  ...   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...  ...   \n",
       "2                                               None  ...   \n",
       "3                                               None  ...   \n",
       "4                                               None  ...   \n",
       "\n",
       "                                      abstract_tfidf cluster_abstract_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                      2   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                      4   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                      2   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                      4   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                      2   \n",
       "\n",
       "                                         title_tfidf cluster_title_tfidf  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                   1   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                   2   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                   2   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                   3   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...                   1   \n",
       "\n",
       "                             abstract_embedding_bert  \\\n",
       "0  [-0.0707399398, 0.2497202158, 0.0697884262, -0...   \n",
       "1  [-0.3843331933, -0.2263615727, 0.2963011265, 0...   \n",
       "2  [-0.3154313266, -0.24923917650000002, -0.32852...   \n",
       "3  [0.040906731, 0.4251708388, -0.162817806, 0.18...   \n",
       "4  [-0.12671619650000002, -0.0426417366, -0.20895...   \n",
       "\n",
       "                    abstract_reduced_embeddings_bert  cluster_abstract_bert  \\\n",
       "0  [-2.0193810463, -2.4993662834, -0.3357081413, ...                      2   \n",
       "1  [1.3566942215, 1.1760284901, 1.6757059097, -1....                      1   \n",
       "2  [-0.27569633720000003, -2.1775341034, 2.087684...                      3   \n",
       "3  [1.2501780987, 1.6642855406, -0.07740855220000...                      1   \n",
       "4  [-0.2887310386, 2.3744587898000002, -0.4303132...                      0   \n",
       "\n",
       "                                title_embedding_bert  \\\n",
       "0  [-0.762732029, -0.5272296667, -0.3555475771, -...   \n",
       "1  [-0.451326102, -0.3827941716, -0.4721180499, -...   \n",
       "2  [-0.48346123100000005, -0.259116143, -0.323963...   \n",
       "3  [-0.5709663033, -0.6318161488, -0.868732035200...   \n",
       "4  [-0.4691320956, -0.2000201046, -0.2584528625, ...   \n",
       "\n",
       "                       title_reduced_embeddings_bert  cluster_title_bert  \n",
       "0  [2.5423688889, -0.6378098726, -1.2343144417, -...                   2  \n",
       "1  [0.7403473854, 0.6475714445, 0.193864598900000...                   4  \n",
       "2  [-1.4785642624, -1.9715181589, 2.7166180611, 0...                   1  \n",
       "3  [3.9551944733, 1.2371120453, -0.20816591380000...                   2  \n",
       "4  [-0.4662218094, -1.8894429207, -0.305285722000...                   3  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c475d7-c727-49ce-93aa-a62c58f79f78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1742256521491,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "e4c475d7-c727-49ce-93aa-a62c58f79f78",
    "outputId": "3f376567-730a-48bd-f2f0-242e0b310852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11597 entries, 0 to 11625\n",
      "Data columns (total 35 columns):\n",
      " #   Column                            Non-Null Count  Dtype \n",
      "---  ------                            --------------  ----- \n",
      " 0   id                                11597 non-null  object\n",
      " 1   submitter                         11597 non-null  object\n",
      " 2   authors                           11597 non-null  object\n",
      " 3   title                             11597 non-null  object\n",
      " 4   comments                          11597 non-null  object\n",
      " 5   journal_ref                       11597 non-null  object\n",
      " 6   doi                               11597 non-null  object\n",
      " 7   report_no                         11597 non-null  object\n",
      " 8   categories                        11597 non-null  object\n",
      " 9   license                           11597 non-null  object\n",
      " 10  abstract                          11597 non-null  object\n",
      " 11  versions                          11597 non-null  object\n",
      " 12  update_date                       11597 non-null  int64 \n",
      " 13  authors_parsed                    11597 non-null  object\n",
      " 14  pdf_url                           11597 non-null  object\n",
      " 15  paper_published                   11597 non-null  int64 \n",
      " 16  update_year                       11597 non-null  int64 \n",
      " 17  newest_date                       11597 non-null  int64 \n",
      " 18  version1_year                     11597 non-null  int64 \n",
      " 19  num_pages                         11597 non-null  int64 \n",
      " 20  num_figures                       11597 non-null  int64 \n",
      " 21  submitter_frequency               11597 non-null  int64 \n",
      " 22  title_keyword_count               11597 non-null  int64 \n",
      " 23  abstract_keyword_count            11597 non-null  int64 \n",
      " 24  comments_keyword_count            11597 non-null  int64 \n",
      " 25  abstract_tfidf                    11597 non-null  object\n",
      " 26  cluster_abstract_tfidf            11597 non-null  int64 \n",
      " 27  title_tfidf                       11597 non-null  object\n",
      " 28  cluster_title_tfidf               11597 non-null  int64 \n",
      " 29  abstract_embedding_bert           11597 non-null  object\n",
      " 30  abstract_reduced_embeddings_bert  11597 non-null  object\n",
      " 31  cluster_abstract_bert             11597 non-null  int64 \n",
      " 32  title_embedding_bert              11597 non-null  object\n",
      " 33  title_reduced_embeddings_bert     11597 non-null  object\n",
      " 34  cluster_title_bert                11597 non-null  int64 \n",
      "dtypes: int64(15), object(20)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "arxiv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edabb86a-97a6-4162-adf0-38e4fde36c8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742256521495,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "edabb86a-97a6-4162-adf0-38e4fde36c8f",
    "outputId": "c3ef04a9-b898-4d71-e268-c23fce14714a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                  object\n",
      "submitter                           object\n",
      "authors                             object\n",
      "title                               object\n",
      "comments                            object\n",
      "journal_ref                         object\n",
      "doi                                 object\n",
      "report_no                           object\n",
      "categories                          object\n",
      "license                             object\n",
      "abstract                            object\n",
      "versions                            object\n",
      "update_date                          int64\n",
      "authors_parsed                      object\n",
      "pdf_url                             object\n",
      "paper_published                      int64\n",
      "update_year                          int64\n",
      "newest_date                          int64\n",
      "version1_year                        int64\n",
      "num_pages                            int64\n",
      "num_figures                          int64\n",
      "submitter_frequency                  int64\n",
      "title_keyword_count                  int64\n",
      "abstract_keyword_count               int64\n",
      "comments_keyword_count               int64\n",
      "abstract_tfidf                      object\n",
      "cluster_abstract_tfidf               int64\n",
      "title_tfidf                         object\n",
      "cluster_title_tfidf                  int64\n",
      "abstract_embedding_bert             object\n",
      "abstract_reduced_embeddings_bert    object\n",
      "cluster_abstract_bert                int64\n",
      "title_embedding_bert                object\n",
      "title_reduced_embeddings_bert       object\n",
      "cluster_title_bert                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(arxiv.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f693bf23-6b07-40f1-a8b2-dd7ee33e319e",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1742256521496,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "f693bf23-6b07-40f1-a8b2-dd7ee33e319e"
   },
   "outputs": [],
   "source": [
    "##### 5. Predictive Modelling - Which Articles Are More Likely to be Published?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38c5cbd6-1e8e-4e3d-bfac-5117ca087c28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742256521532,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "38c5cbd6-1e8e-4e3d-bfac-5117ca087c28",
    "outputId": "8c7d6a1a-0951-47c8-b3a9-f677eb6515c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "paper_published\n",
      "0    9817\n",
      "1    1780\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "###Distinct values of paper_published\n",
    "# Get distinct values of the 'paper_published' column\n",
    "distinct_primary_categories = arxiv['paper_published'].unique()\n",
    "\n",
    "# Convert to a list for better readability\n",
    "distinct_primary_categories_list = distinct_primary_categories.tolist()\n",
    "\n",
    "# Display the distinct values\n",
    "print(distinct_primary_categories_list)\n",
    "\n",
    "# Count occurrences of each unique value in the 'paper_published' column\n",
    "counts = arxiv['paper_published'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d198d1ee-ddfa-45d8-9864-f4d099db4724",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1742256521555,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "d198d1ee-ddfa-45d8-9864-f4d099db4724"
   },
   "outputs": [],
   "source": [
    "# Define numerical and list_of_lists and categorical columns\n",
    "numerical_cols = ['num_pages', 'num_figures', 'submitter_frequency', \n",
    "                  'title_keyword_count', 'abstract_keyword_count',\n",
    "                  'comments_keyword_count', 'update_year', 'version1_year', \n",
    "                  'cluster_abstract_tfidf', 'cluster_title_tfidf', \n",
    "                  'cluster_abstract_bert', 'cluster_title_bert'\n",
    "                  ]\n",
    "\n",
    "list_columns = ['abstract_tfidf', 'title_tfidf',\n",
    "                'abstract_reduced_embeddings_bert', 'title_reduced_embeddings_bert',\n",
    "                'abstract_embedding_bert', 'title_embedding_bert'\n",
    "]\n",
    "\n",
    "numerical_and_list_columns = numerical_cols + list_columns\n",
    "\n",
    "#categorical_cols = ['journal_ref', 'categories', 'license']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69754ae6-11c7-4d3f-a9c5-02b7ffedfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert lists and scale arxiv; save to arxiv_scaled\n",
    "\n",
    "def scale_fit_columns(df, list_columns, numeric_columns):\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Scale list columns\n",
    "    for column in list_columns:\n",
    "        # Check if column exists in DataFrame\n",
    "        if column not in df.columns:\n",
    "            print(f\"Column '{column}' not found in DataFrame. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Check if column contains lists of numbers\n",
    "        if not all(isinstance(x, list) and all(isinstance(y, (int, float)) for y in x) for x in df[column]):\n",
    "            print(f\"Column '{column}' does not contain lists of numbers. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Find the maximum length\n",
    "        max_length = max(len(x) for x in df[column])\n",
    "        \n",
    "        # Pad lists to the same length\n",
    "        padded_lists = [list(x) + [0] * (max_length - len(x)) for x in df[column]]\n",
    "        \n",
    "        # Convert padded lists to NumPy array and scale\n",
    "        padded_arrays = np.array(padded_lists)\n",
    "        scaled_padded_arrays = scaler.fit_transform(padded_arrays)\n",
    "        \n",
    "        # Convert scaled arrays back to lists\n",
    "        scaled_padded_lists = [list(row) for row in scaled_padded_arrays]\n",
    "        \n",
    "        # Update the DataFrame\n",
    "        df[f\"scaled_{column}_padded\"] = scaled_padded_lists\n",
    "    \n",
    "    # Scale numeric columns\n",
    "    for column in numeric_columns:\n",
    "        # Check if column exists in DataFrame\n",
    "        if column not in df.columns:\n",
    "            print(f\"Column '{column}' not found in DataFrame. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Check if column contains numeric values\n",
    "        if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "            print(f\"Column '{column}' does not contain numeric values. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Scale the column\n",
    "        df[f\"scaled_{column}\"] = scaler.fit_transform(df[[column]])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "arxiv_scaled = scale_fit_columns(arxiv, list_columns, numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80cade15-370c-421a-8e8b-851338d0e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold all new feature DataFrames\n",
    "new_feature_dfs = []\n",
    "\n",
    "# Convert list columns into separate features\n",
    "for column in list_columns:\n",
    "    # Pad lists to the same length\n",
    "    max_length = max(len(x) for x in arxiv_scaled[column])\n",
    "    padded_lists = [list(x) + [0] * (max_length - len(x)) for x in arxiv_scaled[column]]\n",
    "    \n",
    "    # Create DataFrame for features\n",
    "    padded_array = np.array(padded_lists)\n",
    "    feature_df = pd.DataFrame(\n",
    "        padded_array,\n",
    "        columns=[f\"{column}_feature_{i}\" for i in range(padded_array.shape[1])],\n",
    "        index=arxiv_scaled.index\n",
    "    )\n",
    "    \n",
    "    new_feature_dfs.append(feature_df)\n",
    "\n",
    "# Concatenate all new features at once\n",
    "arxiv_scaled = pd.concat(\n",
    "    [arxiv_scaled] + new_feature_dfs,\n",
    "    axis=1).copy()  # The copy() helps with defragmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb8eabe8-4d7e-40cd-b572-3efee31ff5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original list columns\n",
    "arxiv_scaled.drop(columns=list_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3953f460-fdba-4d64-acfb-e9dc68accfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Scale based on affinity of columns - givenby the prefix usedc to create the columns\n",
    "### Define the function to sum columns based on prefixes\n",
    "def combine_columns_by_prefix(df, prefixes, output_columns):\n",
    "    for prefix, output_column in zip(prefixes, output_columns):\n",
    "        # Find columns that start with the given prefix\n",
    "        matching_columns = [col for col in df.columns if col.startswith(prefix)]\n",
    "        \n",
    "        # Sum the values of the matching columns; make sure it's positive with abs()\n",
    "        df[output_column] = df[matching_columns].sum(axis=1, min_count=1).abs()\n",
    "    return df\n",
    "\n",
    "# Define prefixes and output column names\n",
    "prefixes = ['abstract_t', 'title_t', 'abstract_r', 'title_r', 'abstract_e', 'title_e']\n",
    "\n",
    "output_columns = [\n",
    "    'abstract_tfidf_feature_combined',\n",
    "    'title_tfidf_feature_combined',\n",
    "    'abstract_reduced_embeddings_bert_feature_combined',\n",
    "    'title_reduced_embeddings_bert_feature_combined',\n",
    "    'abstract_embedding_bert_feature_combined',\n",
    "    'title_embedding_bert_feature_combined'\n",
    "]\n",
    "\n",
    "### Apply the function to the arxiv_scaled DataFrame\n",
    "arxiv_scaled = combine_columns_by_prefix(arxiv_scaled, prefixes, output_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34349fc3-82d0-4f91-b638-528beb7340e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Verify the new columns\n",
    "#print(arxiv_scaled[output_columns].head())\n",
    "\n",
    "# Check if arxiv_scaled is defined\n",
    "#if 'arxiv_scaled' in locals():\n",
    "#    num_columns = len(arxiv_scaled.columns)\n",
    "#    print(f\"Number of columns in arxiv_scaled: {num_columns}\")\n",
    "#else:\n",
    "#    print(\"arxiv_scaled is not defined.\")\n",
    "\n",
    "#arxiv_scaled.head()\n",
    "#arxiv_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "444f043c-d971-4f35-b23f-d9c803efa5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns dropped: 11792\n"
     ]
    }
   ],
   "source": [
    "### Drop columns whose names start with any of the prefixes, excluding those in list_output_feature_columns\n",
    "columns_to_drop = [col for col in arxiv_scaled.columns \n",
    "                   if any(col.startswith(prefix) for prefix in prefixes) \n",
    "                   and col not in output_columns]\n",
    "\n",
    "arxiv_scaled.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "#Plot number of columns dropped\n",
    "num_columns_dropped = len(columns_to_drop)\n",
    "print(f\"Number of columns dropped: {num_columns_dropped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b7b74b2-947e-4aad-91a9-c45a198689b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: ['id', 'submitter', 'authors', 'title', 'comments', 'journal_ref', 'doi', 'report_no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed', 'pdf_url', 'paper_published', 'update_year', 'newest_date', 'version1_year', 'num_pages', 'num_figures', 'submitter_frequency', 'title_keyword_count', 'abstract_keyword_count', 'comments_keyword_count', 'cluster_abstract_tfidf', 'cluster_title_tfidf', 'cluster_abstract_bert', 'cluster_title_bert', 'abstract_tfidf_feature_combined', 'title_tfidf_feature_combined', 'abstract_reduced_embeddings_bert_feature_combined', 'title_reduced_embeddings_bert_feature_combined', 'abstract_embedding_bert_feature_combined', 'title_embedding_bert_feature_combined']\n"
     ]
    }
   ],
   "source": [
    "###drop \"old\" scaled columns\n",
    "# Check if arxiv_scaled is defined\n",
    "if 'arxiv_scaled' in locals():\n",
    "    # Identify columns to drop\n",
    "    columns_to_drop = [col for col in arxiv_scaled.columns if col.startswith('scaled_')]\n",
    "    \n",
    "    # Drop the identified columns\n",
    "    arxiv_scaled = arxiv_scaled.drop(columns=columns_to_drop, inplace=False)\n",
    "    \n",
    "    # Output the remaining columns\n",
    "    remaining_columns = arxiv_scaled.columns.tolist()\n",
    "    print(\"Remaining columns:\", remaining_columns)\n",
    "else:\n",
    "    print(\"arxiv_scaled is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aaa9b4a-aa41-4ee5-8a44-11b695c5788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the output feature columns by combining the scaled features\n",
    "\n",
    "numerical_cols = ['num_pages', 'num_figures', 'submitter_frequency', \n",
    "                  'title_keyword_count', 'abstract_keyword_count',\n",
    "                  'comments_keyword_count', 'update_year', 'version1_year', \n",
    "                  'cluster_abstract_tfidf', 'cluster_title_tfidf', \n",
    "                  'cluster_abstract_bert', 'cluster_title_bert'\n",
    "                  ]\n",
    "\n",
    "list_columns = [\n",
    "    'abstract_tfidf_feature_combined',\n",
    "    'title_tfidf_feature_combined',\n",
    "    'abstract_reduced_embeddings_bert_feature_combined',\n",
    "    'title_reduced_embeddings_bert_feature_combined',\n",
    "    'abstract_embedding_bert_feature_combined',\n",
    "    'title_embedding_bert_feature_combined'\n",
    "]\n",
    "\n",
    "#Combine features\n",
    "numerical_and_list_columns = numerical_cols + list_columns\n",
    "#numerical_and_list_columns = numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8a15e79-5ae6-4e6c-af5f-b2eb1f67cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'submitter', 'authors', 'title', 'comments', 'journal_ref', 'doi', 'report_no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed', 'pdf_url', 'paper_published', 'update_year', 'newest_date', 'version1_year', 'num_pages', 'num_figures', 'submitter_frequency', 'title_keyword_count', 'abstract_keyword_count', 'comments_keyword_count', 'cluster_abstract_tfidf', 'cluster_title_tfidf', 'cluster_abstract_bert', 'cluster_title_bert', 'abstract_tfidf_feature_combined', 'title_tfidf_feature_combined', 'abstract_reduced_embeddings_bert_feature_combined', 'title_reduced_embeddings_bert_feature_combined', 'abstract_embedding_bert_feature_combined', 'title_embedding_bert_feature_combined']\n"
     ]
    }
   ],
   "source": [
    "### Output of the updated DataFrame columns\n",
    "print(arxiv_scaled.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f75dab1-93ba-42b1-9dd5-4865234d5e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report_no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_abstract_tfidf</th>\n",
       "      <th>cluster_title_tfidf</th>\n",
       "      <th>cluster_abstract_bert</th>\n",
       "      <th>cluster_title_bert</th>\n",
       "      <th>abstract_tfidf_feature_combined</th>\n",
       "      <th>title_tfidf_feature_combined</th>\n",
       "      <th>abstract_reduced_embeddings_bert_feature_combined</th>\n",
       "      <th>title_reduced_embeddings_bert_feature_combined</th>\n",
       "      <th>abstract_embedding_bert_feature_combined</th>\n",
       "      <th>title_embedding_bert_feature_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.1394</td>\n",
       "      <td>Tarik Hadvzic</td>\n",
       "      <td>Tarik Hadzic Rune Moller Jensen Henrik Reif An...</td>\n",
       "      <td>Calculating Valid Domains for BDDBased Interac...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.339616</td>\n",
       "      <td>2.508605</td>\n",
       "      <td>0.514960</td>\n",
       "      <td>2.867864</td>\n",
       "      <td>6.452453</td>\n",
       "      <td>7.462064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.201</td>\n",
       "      <td>Juliana Bernardes</td>\n",
       "      <td>Juliana S Bernardes Alberto Davila Vitor Santo...</td>\n",
       "      <td>A study of structural properties on profiles HMMs</td>\n",
       "      <td>6 pages, 7 figures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8.824050</td>\n",
       "      <td>2.297803</td>\n",
       "      <td>0.380061</td>\n",
       "      <td>8.640687</td>\n",
       "      <td>7.046748</td>\n",
       "      <td>6.688396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.3433</td>\n",
       "      <td>Tshilidzi Marwala</td>\n",
       "      <td>Tshilidzi Marwala and Bodie Crossingham</td>\n",
       "      <td>Bayesian approach to rough set</td>\n",
       "      <td>20 pages, 3 figures</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.069886</td>\n",
       "      <td>2.186416</td>\n",
       "      <td>2.640302</td>\n",
       "      <td>1.810724</td>\n",
       "      <td>7.616964</td>\n",
       "      <td>7.551085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.3515</td>\n",
       "      <td>Jegor Uglov Mr</td>\n",
       "      <td>J Uglov V Schetinin C Maple</td>\n",
       "      <td>Comparing Robustness of Pairwise and Multiclas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10.1155/2008/468693</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.737238</td>\n",
       "      <td>3.045996</td>\n",
       "      <td>4.420754</td>\n",
       "      <td>4.224183</td>\n",
       "      <td>6.616488</td>\n",
       "      <td>8.452498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.3905</td>\n",
       "      <td>Marc Schoenauer</td>\n",
       "      <td>Christian Gagne INFORMATIQUE WGZ INC Michele S...</td>\n",
       "      <td>Ensemble Learning for Free with Evolutionary A...</td>\n",
       "      <td>None</td>\n",
       "      <td>Dans GECCO (2007)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.184695</td>\n",
       "      <td>2.431577</td>\n",
       "      <td>1.794670</td>\n",
       "      <td>0.696287</td>\n",
       "      <td>7.978225</td>\n",
       "      <td>6.603048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          submitter  \\\n",
       "0  704.1394      Tarik Hadvzic   \n",
       "1   704.201  Juliana Bernardes   \n",
       "2  704.3433  Tshilidzi Marwala   \n",
       "3  704.3515     Jegor Uglov Mr   \n",
       "4  704.3905    Marc Schoenauer   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Tarik Hadzic Rune Moller Jensen Henrik Reif An...   \n",
       "1  Juliana S Bernardes Alberto Davila Vitor Santo...   \n",
       "2            Tshilidzi Marwala and Bodie Crossingham   \n",
       "3                        J Uglov V Schetinin C Maple   \n",
       "4  Christian Gagne INFORMATIQUE WGZ INC Michele S...   \n",
       "\n",
       "                                               title             comments  \\\n",
       "0  Calculating Valid Domains for BDDBased Interac...                 None   \n",
       "1  A study of structural properties on profiles HMMs   6 pages, 7 figures   \n",
       "2                     Bayesian approach to rough set  20 pages, 3 figures   \n",
       "3  Comparing Robustness of Pairwise and Multiclas...                 None   \n",
       "4  Ensemble Learning for Free with Evolutionary A...                 None   \n",
       "\n",
       "         journal_ref                  doi report_no categories  \\\n",
       "0               None                 None      None      cs.AI   \n",
       "1               None                 None      None      cs.AI   \n",
       "2               None                 None      None      cs.AI   \n",
       "3               None  10.1155/2008/468693      None      cs.AI   \n",
       "4  Dans GECCO (2007)                 None      None      cs.AI   \n",
       "\n",
       "                                             license  ...  \\\n",
       "0                                               None  ...   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...  ...   \n",
       "2                                               None  ...   \n",
       "3                                               None  ...   \n",
       "4                                               None  ...   \n",
       "\n",
       "  cluster_abstract_tfidf cluster_title_tfidf  cluster_abstract_bert  \\\n",
       "0                      2                   1                      2   \n",
       "1                      4                   2                      1   \n",
       "2                      2                   2                      3   \n",
       "3                      4                   3                      1   \n",
       "4                      2                   1                      0   \n",
       "\n",
       "  cluster_title_bert abstract_tfidf_feature_combined  \\\n",
       "0                  2                        4.339616   \n",
       "1                  4                        8.824050   \n",
       "2                  1                        7.069886   \n",
       "3                  2                        5.737238   \n",
       "4                  3                        7.184695   \n",
       "\n",
       "   title_tfidf_feature_combined  \\\n",
       "0                      2.508605   \n",
       "1                      2.297803   \n",
       "2                      2.186416   \n",
       "3                      3.045996   \n",
       "4                      2.431577   \n",
       "\n",
       "   abstract_reduced_embeddings_bert_feature_combined  \\\n",
       "0                                           0.514960   \n",
       "1                                           0.380061   \n",
       "2                                           2.640302   \n",
       "3                                           4.420754   \n",
       "4                                           1.794670   \n",
       "\n",
       "   title_reduced_embeddings_bert_feature_combined  \\\n",
       "0                                        2.867864   \n",
       "1                                        8.640687   \n",
       "2                                        1.810724   \n",
       "3                                        4.224183   \n",
       "4                                        0.696287   \n",
       "\n",
       "   abstract_embedding_bert_feature_combined  \\\n",
       "0                                  6.452453   \n",
       "1                                  7.046748   \n",
       "2                                  7.616964   \n",
       "3                                  6.616488   \n",
       "4                                  7.978225   \n",
       "\n",
       "   title_embedding_bert_feature_combined  \n",
       "0                               7.462064  \n",
       "1                               6.688396  \n",
       "2                               7.551085  \n",
       "3                               8.452498  \n",
       "4                               6.603048  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec96a2c4-c7e9-476f-9291-ac79e095afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11597 entries, 0 to 11625\n",
      "Data columns (total 35 columns):\n",
      " #   Column                                             Non-Null Count  Dtype  \n",
      "---  ------                                             --------------  -----  \n",
      " 0   id                                                 11597 non-null  object \n",
      " 1   submitter                                          11597 non-null  object \n",
      " 2   authors                                            11597 non-null  object \n",
      " 3   title                                              11597 non-null  object \n",
      " 4   comments                                           11597 non-null  object \n",
      " 5   journal_ref                                        11597 non-null  object \n",
      " 6   doi                                                11597 non-null  object \n",
      " 7   report_no                                          11597 non-null  object \n",
      " 8   categories                                         11597 non-null  object \n",
      " 9   license                                            11597 non-null  object \n",
      " 10  abstract                                           11597 non-null  object \n",
      " 11  versions                                           11597 non-null  object \n",
      " 12  update_date                                        11597 non-null  int64  \n",
      " 13  authors_parsed                                     11597 non-null  object \n",
      " 14  pdf_url                                            11597 non-null  object \n",
      " 15  paper_published                                    11597 non-null  int64  \n",
      " 16  update_year                                        11597 non-null  int64  \n",
      " 17  newest_date                                        11597 non-null  int64  \n",
      " 18  version1_year                                      11597 non-null  int64  \n",
      " 19  num_pages                                          11597 non-null  int64  \n",
      " 20  num_figures                                        11597 non-null  int64  \n",
      " 21  submitter_frequency                                11597 non-null  int64  \n",
      " 22  title_keyword_count                                11597 non-null  int64  \n",
      " 23  abstract_keyword_count                             11597 non-null  int64  \n",
      " 24  comments_keyword_count                             11597 non-null  int64  \n",
      " 25  cluster_abstract_tfidf                             11597 non-null  int64  \n",
      " 26  cluster_title_tfidf                                11597 non-null  int64  \n",
      " 27  cluster_abstract_bert                              11597 non-null  int64  \n",
      " 28  cluster_title_bert                                 11597 non-null  int64  \n",
      " 29  abstract_tfidf_feature_combined                    11597 non-null  float64\n",
      " 30  title_tfidf_feature_combined                       11597 non-null  float64\n",
      " 31  abstract_reduced_embeddings_bert_feature_combined  11597 non-null  float64\n",
      " 32  title_reduced_embeddings_bert_feature_combined     11597 non-null  float64\n",
      " 33  abstract_embedding_bert_feature_combined           11597 non-null  float64\n",
      " 34  title_embedding_bert_feature_combined              11597 non-null  float64\n",
      "dtypes: float64(6), int64(15), object(14)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "arxiv_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bc6df44-08a3-477e-9ab9-809c4aeb26f2",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1742256521558,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "6bc6df44-08a3-477e-9ab9-809c4aeb26f2"
   },
   "outputs": [],
   "source": [
    "# Define features (X) and target (y) of the scaled dataframe\n",
    "X = arxiv_scaled[numerical_and_list_columns]\n",
    "y = arxiv_scaled['paper_published']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e504745-097c-4ee8-b13d-2014ac462030",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742256521562,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "6e504745-097c-4ee8-b13d-2014ac462030"
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Without SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)  # With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc9fdaf2-8dc1-47be-9761-4dc3cc10513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE Define resampling strategy\n",
    "over_sample = SMOTE(sampling_strategy=0.5)  # 50% minority class\n",
    "under_sample = RandomUnderSampler(sampling_strategy=0.8)  # 80% majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fa6d825-0df2-4cad-ad76-1d352db3592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a1456b3-fad2-4732-920a-0e5894585f96",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742256521597,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "1a1456b3-fad2-4732-920a-0e5894585f96"
   },
   "outputs": [],
   "source": [
    "### Define models using default parameters\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=5000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Neural Network': MLPClassifier(max_iter=5000)\n",
    "}\n",
    "\n",
    "### Define models with resampling pipeline - SMOTE\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('over', over_sample),\n",
    "        ('under', under_sample),\n",
    "        ('model', LogisticRegression(class_weight='balanced', max_iter=5000))\n",
    "    ]),\n",
    "    'Decision Tree': Pipeline([\n",
    "        ('over', over_sample),\n",
    "        ('under', under_sample),\n",
    "        ('model', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('over', over_sample),\n",
    "        ('under', under_sample),\n",
    "        ('model', RandomForestClassifier())\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('over', over_sample),\n",
    "        ('under', under_sample),\n",
    "        ('model', SVC())\n",
    "    ]),\n",
    "    'KNN': Pipeline([\n",
    "        ('over', over_sample),\n",
    "        ('under', under_sample),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'Naive Bayes': Pipeline([\n",
    "        ('over', over_sample),\n",
    "        ('under', under_sample),\n",
    "        ('model', MultinomialNB())\n",
    "    ]),\n",
    "    'Gradient Boosting': Pipeline([\n",
    "        ('over', over_sample),\n",
    "        ('under', under_sample),\n",
    "        ('model', GradientBoostingClassifier())\n",
    "    ]),\n",
    "    'Neural Network': Pipeline([\n",
    "        ('over', over_sample),\n",
    "        ('under', under_sample),\n",
    "        ('model', MLPClassifier(max_iter=5000))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ced0b166-5db7-4775-9883-320991220341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the optimized hyperparameters for each model\n",
    "optimized_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c04f727a-9107-4150-a9e0-63f7cfa629da",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1742256521623,
     "user": {
      "displayName": "Fernando Nimer",
      "userId": "02382746642520573838"
     },
     "user_tz": 240
    },
    "id": "c04f727a-9107-4150-a9e0-63f7cfa629da"
   },
   "outputs": [],
   "source": [
    "#### Define hyperparameter grids for each model nd perform GridSearchCV for all models\n",
    "\n",
    "#Define parameters\n",
    "param_grids = {\n",
    "    'Logistic Regression':{\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'penalty': ['l1'],\n",
    "        'solver': ['liblinear'],\n",
    "        'tol': [1e-6],\n",
    "        'max_iter': [1000]\n",
    "},\n",
    "    'Decision Tree': {\n",
    "        'criterion': ['gini'],\n",
    "        'max_depth': [5],\n",
    "        'min_samples_split': [2],\n",
    "        'min_samples_leaf': [1]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [5, 10, None]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [5],\n",
    "        'weights': ['uniform'],\n",
    "        'algorithm': ['auto']\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'alpha': [0.1, 0.5, 1.0, 2.0],  # Smoothing parameter\n",
    "        'fit_prior': [True, False]  # Whether to learn class prior probabilities\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50],\n",
    "        'learning_rate': [0.1],\n",
    "        'max_depth': [5],\n",
    "        'min_samples_split': [2],\n",
    "        'min_samples_leaf': [1]\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'hidden_layer_sizes': [(20,)],\n",
    "        'activation': ['relu'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001],\n",
    "        'max_iter': [1000]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d5ba690-e768-4509-bb61-1fce4c7de064",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform GridSearchCV for each model\n",
    "#for name, model in models.items():\n",
    "#    if name in param_grids:\n",
    "#        grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='accuracy', error_score='raise')\n",
    "#        grid_search.fit(X_train, y_train)\n",
    "#        optimized_models[name] = grid_search.best_estimator_\n",
    "#    else:\n",
    "#        optimized_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "043d6db1-f9dd-4bcb-9973-37851a37864b",
   "metadata": {
    "id": "043d6db1-f9dd-4bcb-9973-37851a37864b"
   },
   "outputs": [],
   "source": [
    "### Print results of hyperparameters for each model\n",
    "#for name, model in optimized_models.items():\n",
    "#    print(f\"Optimized {name}:\")\n",
    "#    print(model.get_params())\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1607ed20-8a60-4ace-8775-6c38650756f1",
   "metadata": {
    "id": "1607ed20-8a60-4ace-8775-6c38650756f1"
   },
   "outputs": [],
   "source": [
    "### Adjust models to selected hyperparameters\n",
    "\n",
    "#New parameters, adjusted post GridSearchCV\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [100],                  # From optimized LogisticRegression\n",
    "        'penalty': ['l1'],           # Matches optimized penalty\n",
    "        'solver': ['liblinear'],     # Correct solver for L1 regularization\n",
    "        'max_iter': [1000],          # Keep optimized iteration count\n",
    "        'class_weight': [None],      # From optimization\n",
    "        'tol': [1e-06]               # Matches optimized tolerance\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'criterion': ['gini'],       # From optimized DecisionTree\n",
    "        'max_depth': [5],            # Matches optimized depth constraint\n",
    "        'min_samples_split': [2],    # Maintains optimized split policy\n",
    "        'min_samples_leaf': [1]      # Matches leaf node requirements\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [200],       # From optimized RandomForest\n",
    "        'max_features': ['sqrt'],    # Matches feature selection strategy\n",
    "        'bootstrap': [True],         # Maintain optimized resampling method\n",
    "        'min_samples_split': [2],    # Keep optimized split threshold\n",
    "        'min_samples_leaf': [1]      # Matches leaf node requirements\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1],                  # From optimized SVM parameters\n",
    "        'kernel': ['linear'],        # Matches optimized kernel type\n",
    "        'gamma': ['scale'],          # Maintain optimized scaling\n",
    "        'tol': [0.001]               # Keep convergence tolerance\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [5],          # From optimized KNN\n",
    "        'weights': ['uniform'],      # Matches weighting strategy\n",
    "        'algorithm': ['auto']        # Maintain automatic algorithm selection\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'alpha': [0.1],              # From optimized NaiveBayes\n",
    "        'fit_prior': [True]          # Matches prior learning strategy\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50],        # From optimized GradientBoosting\n",
    "        'learning_rate': [0.1],      # Matches optimized learning rate\n",
    "        'max_depth': [5],            # Keep optimized depth constraint\n",
    "        'min_samples_split': [2],    # Maintain split requirements\n",
    "        'min_samples_leaf': [1]      # Match leaf node policy\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'hidden_layer_sizes': [(20,)],  # From optimized architecture\n",
    "        'activation': ['relu'],      # Matches activation function\n",
    "        'solver': ['adam'],          # Keep optimized solver\n",
    "        'alpha': [0.0001],           # Matches regularization strength\n",
    "        'max_iter': [1000],          # Maintain iteration count\n",
    "        'tol': [0.0001]              # Keep convergence tolerance\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbcccf-dba5-4822-9804-96aae7e00ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and evaluate each model with adjusted hyperparameters and SFS - feature selection\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "# Apply SFS with critical optimizations\n",
    "for name, model in models.items():\n",
    "    # Configure common SFS parameters\n",
    "    sfs_params = {\n",
    "        'n_features_to_select': 0.5,    # Explicit ratio instead of 'auto'\n",
    "        'direction': 'forward',         # Consider bidirectional if relevant\n",
    "        'scoring': 'accuracy',\n",
    "        'cv': 3,                        # Reduced from 5 folds\n",
    "        'n_jobs': -1,                   # Enable parallel processing\n",
    "        'tol': 0.01                     # Early stopping tolerance\n",
    "    }\n",
    "    \n",
    "    # Create appropriate pipeline\n",
    "    if name in ['Logistic Regression', 'SVM', 'Neural Network']:\n",
    "        # Pipeline with scaling for sensitive models\n",
    "        pipeline = make_pipeline(StandardScaler(), model)\n",
    "        sfs = SequentialFeatureSelector(pipeline, **sfs_params)\n",
    "    else:\n",
    "        # Direct model for tree-based algorithms\n",
    "        sfs = SequentialFeatureSelector(model, **sfs_params)\n",
    "    \n",
    "    # Fit SFS and transform data\n",
    "    sfs.fit(X_train, y_train)\n",
    "    X_train_sfs = sfs.transform(X_train)\n",
    "    X_test_sfs = sfs.transform(X_test)\n",
    "    \n",
    "    # Train final model with proper preprocessing\n",
    "    if name in ['Logistic Regression', 'SVM', 'Neural Network']:\n",
    "        pipeline.fit(X_train_sfs, y_train)\n",
    "        y_pred_test = pipeline.predict(X_test_sfs)\n",
    "        y_pred_train = pipeline.predict(X_train_sfs)\n",
    "    else:\n",
    "        model.fit(X_train_sfs, y_train)\n",
    "        y_pred_test = model.predict(X_test_sfs)\n",
    "        y_pred_train = model.predict(X_train_sfs)\n",
    "        \n",
    "        # Train model with selected features\n",
    "        model.fit(X_train_sfs, y_train)\n",
    "        y_pred_train = model.predict(X_train_sfs)\n",
    "        y_pred_test = model.predict(X_test_sfs)\n",
    "\n",
    "    # Get selected feature names (if using pandas DataFrame)\n",
    "    try:\n",
    "        selected_features = X_train.columns[sfs.get_support()].tolist()\n",
    "    except AttributeError:\n",
    "        selected_features = sfs.get_support(indices=True).tolist()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision = precision_score(y_test, y_pred_test)\n",
    "    recall = recall_score(y_test, y_pred_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred_test)\n",
    "    TN, FP, FN, TP = conf_mat.ravel()\n",
    "    bias = (TP / (TP + FN)) - (FP / (FP + TN)) if (TP + FN) != 0 and (FP + TN) != 0 else 0\n",
    "    variance = np.var(y_pred_test)\n",
    "\n",
    "    # Append results with feature selection info\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Selected Features': selected_features,\n",
    "        'Num Features': len(selected_features),\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'True Positives (TP)': TP,\n",
    "        'False Positives (FP)': FP,\n",
    "        'True Negatives (TN)': TN,\n",
    "        'False Negatives (FN)': FN,\n",
    "        'Bias': bias,\n",
    "        'Variance': variance\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e36c27-4e00-4f24-8e5e-ffe4155b91e1",
   "metadata": {
    "id": "72e36c27-4e00-4f24-8e5e-ffe4155b91e1"
   },
   "outputs": [],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9b422-f833-496f-bd55-0a16079147fd",
   "metadata": {
    "id": "6bc9b422-f833-496f-bd55-0a16079147fd"
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by Accuracy in descending order\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec03aac-a355-4efe-9aaf-a473528be28d",
   "metadata": {
    "id": "aec03aac-a355-4efe-9aaf-a473528be28d"
   },
   "outputs": [],
   "source": [
    "### Save results to a CSV file\n",
    "# Change folder to store the output\n",
    "folder = 'C:/Users/mnkub/Desktop/Capstone/results/'  # Define the folder where images will be saved\n",
    "#folder = '../results/')  # Define the folder where images will be saved\n",
    "\n",
    "filename = 'model_performance_feature_selection.csv'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Create the filename dynamically and save figure\n",
    "filepath = os.path.join(folder, filename)\n",
    "results_df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06dd98-ef51-469d-9369-72c39ed99252",
   "metadata": {
    "id": "8a06dd98-ef51-469d-9369-72c39ed99252"
   },
   "outputs": [],
   "source": [
    "# Display the DataFrame with formatting\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e42cd-7a73-4055-8cae-9a8e7d64c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print formatted features table per model\n",
    "\n",
    "# Expand the Selected Features into separate columns\n",
    "features_expanded = results_df['Selected Features'].apply(pd.Series)\n",
    "\n",
    "# Combine the Model column with the expanded features\n",
    "expanded_table = pd.concat([results_df['Model'], features_expanded], axis=1)\n",
    "\n",
    "# Rename the columns for clarity\n",
    "expanded_table.columns = ['Model'] + [f'Feature #{i+1}' for i in range(features_expanded.shape[1])]\n",
    "\n",
    "# Print the table in a formatted way using tabulate\n",
    "print(tabulate(expanded_table.fillna(''), headers='keys', tablefmt='grid'))\n",
    "\n",
    "# Save the expanded table to a CSV file\n",
    "filename = 'formatted_features_table.xlsx'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# Create the filename dynamically and save figure\n",
    "filepath = os.path.join(folder, filename)\n",
    "expanded_table.to_excel(filepath, index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02faa72f-9c45-4ee3-a2dc-b8adff99832a",
   "metadata": {
    "id": "02faa72f-9c45-4ee3-a2dc-b8adff99832a"
   },
   "outputs": [],
   "source": [
    "### Plot Metrics Results\n",
    "#results_df = pd.DataFrame(data)\n",
    "\n",
    "# Plotting the metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot each metric\n",
    "for metric in metrics:\n",
    "    ax.plot(results_df['Model'], results_df[metric], marker='o', label=metric)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_title('Model Performance Metrics - Higher Accuracy on the Left')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Score')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot dynamically\n",
    "filename = f\"Model_Performance_Metrics.png\"\n",
    "filepath = os.path.join(folder, filename)\n",
    "plt.savefig(filepath)  # Save figure\n",
    "#plt.savefig('../results/Model_Performance_Metrics.png') #adjust folder when fisnihed using the GIT structure\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3468c-e915-4d5e-9ee7-76ae4a007347",
   "metadata": {
    "id": "fbc3468c-e915-4d5e-9ee7-76ae4a007347"
   },
   "outputs": [],
   "source": [
    "###Plot Bias X Variance (note useful for all models)\n",
    "# Plotting Bias and Variance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot Bias\n",
    "ax.plot(results_df['Model'], results_df['Bias'], marker='o', label='Bias', color='blue')\n",
    "\n",
    "# Plot Variance\n",
    "ax.plot(results_df['Model'], results_df['Variance'], marker='o', label='Variance', color='orange')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_title('Bias and Variance for Each Model - Higher Accuracy on the Left')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Value')\n",
    "ax.legend()\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot dynamically\n",
    "filename = f\"Model_Bias_vs_Variance.png\"\n",
    "filepath = os.path.join(folder, filename)\n",
    "plt.savefig(filepath)  # Save figure\n",
    "#plt.savefig('../results/Model_Bias_vs_Variance.png') #adjust folder when fisnihed using the GIT structure\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9cb64-74f1-43cb-8679-48f3d77b60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plot confusion matrix\n",
    "\n",
    "# Create subplot grid for 8 models (2 rows x 4 columns)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "axes = axes.ravel()  # Flatten the 2x4 grid to 1D array\n",
    "\n",
    "# Create confusion matrices from results\n",
    "for idx, result in enumerate(results):\n",
    "    # Extract values from results\n",
    "    model_name = result['Model']\n",
    "    TN = result['True Negatives (TN)']\n",
    "    FP = result['False Positives (FP)']\n",
    "    FN = result['False Negatives (FN)']\n",
    "    TP = result['True Positives (TP)']\n",
    "    \n",
    "    # Create confusion matrix array\n",
    "    conf_mat = np.array([[TN, FP],\n",
    "                         [FN, TP]])\n",
    "    \n",
    "    # Create ConfusionMatrixDisplay\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat,\n",
    "                                  display_labels=['Negative', 'Positive'])\n",
    "    \n",
    "    # Plot on corresponding axis\n",
    "    disp.plot(ax=axes[idx], colorbar=False)\n",
    "    axes[idx].set_title(model_name, fontsize=12, pad=10)\n",
    "    axes[idx].tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "# Remove empty subplot (if odd number of models)\n",
    "if len(results) % 4 != 0:\n",
    "    for ax in axes[len(results):]:\n",
    "        ax.remove()\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "# Save the plot dynamically\n",
    "filename = f\"Confusion_Matrices.png\"\n",
    "filepath = os.path.join(folder, filename)\n",
    "plt.savefig(filepath)  # Save figure\n",
    "#plt.savefig('../results/confusion_matrices.png') #adjust folder when fisnihed using the GIT structure\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5247daa5-0b3d-4631-a7a1-da33e19d9fe8",
   "metadata": {
    "id": "1ccf37a3"
   },
   "source": [
    "###END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
